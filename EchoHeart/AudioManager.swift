import AVFoundation
import Accelerate
import Combine
import NotificationCenter




class AudioManager: ObservableObject {
    private var audioEngine = AVAudioEngine()
    //    private var eqNode = AVAudioUnitEQ(numberOfBands: 1)
    // ä¿®æ­£å¾Œï¼ˆãƒãƒ³ãƒ‰æ•°ã‚’3ã¤æŒ‡å®šã™ã‚‹ï¼‰
    private var eqNode = AVAudioUnitEQ(numberOfBands: 3)
    private var isRunning = false
//    private var isStarting = true
    private var cancellables = Set<AnyCancellable>()
    private let barCount = 15
    private var inputFormat: AVAudioFormat?
    private let mainMixer: AVAudioMixerNode
    
    @Published var spectrumLevels: [Float]
    
    @Published var inputLevel: Float = 0.0  // 0ã€œ1ã®ç¯„å›²
    @Published var currentLevel: Float = 0.0
    private var levelTimer: Timer?
    private var isMonitoring = false
    private var _currentRawLevel: Float = 0.0 // ã“ã“ã«ç”Ÿã®ãƒ¬ãƒ™ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
    private var levelUpdateTimer: Timer? // ã‚¿ã‚¤ãƒãƒ¼ã‚’ä¿æŒã™ã‚‹ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    
    @Published var masterVolume: Float {
        didSet {
            mainMixer.outputVolume = masterVolume
            UserDefaults.standard.set(masterVolume, forKey: "masterVolume")
        }
    }
    
    @Published var lowGain: Float = 0.0 {
        didSet {
            eqNode.bands[0].gain = lowGain
            UserDefaults.standard.set(lowGain, forKey: "lowGain")
        }
    }
    @Published var midGain: Float = 0.0 {
        didSet {
            eqNode.bands[1].gain = midGain
            UserDefaults.standard.set(midGain, forKey: "midGain")
        }
    }
    @Published var highGain: Float = 0.0 {
        didSet {
            eqNode.bands[2].gain = highGain
            UserDefaults.standard.set(highGain, forKey: "highGain")
        }
    }
    @Published var selectedListenMode: listenMode = .ambient { // å¤‰æ•°åã‚’listenModeã‹ã‚‰selectedListenModeã«å¤‰ãˆã¦ã¿ãŸã‚ˆã€åŒºåˆ¥ã—ã‚„ã™ããªã‚‹ã‹ã‚‰ã­
        didSet {
            // ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
            setupAudioSessionForAppLaunch(newListenMode: selectedListenMode)
            if isRunning { // éŒ²éŸ³ä¸­ãªã‚‰â€¦
                // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä¸€åº¦åœæ­¢ãƒ»ãƒªã‚»ãƒƒãƒˆã—ã¦ã€å†èµ·å‹•ã™ã‚‹å‡¦ç†ã‚‚ã“ã“ã«å…¥ã‚Œã‚‹ã¨ã„ã„ã‹ã‚‚
                self.audioEngine.stop()
                self.audioEngine.reset()
                isRunning = false
                self.startMicrophone { success in
                    if success {
                        self.isRunning = true
                    } else {
                        self.stopMicrophone()
                    }
                }
            }
            // listenModeã®Raw Valueï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’ä¿å­˜ã™ã‚‹
            UserDefaults.standard.set(selectedListenMode.rawValue, forKey: "listenMode")
        }
    }
    func setupAudioSessionForAppLaunch(newListenMode: listenMode) {
        do {
            let session = AVAudioSession.sharedInstance()
            switch newListenMode {
            case .ambient:
                try session.setCategory(.playAndRecord, mode: .default, options: [.allowBluetoothA2DP, ])
                print("âœ… ç’°å¢ƒéŸ³ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
            case .conversation:
                try session.setCategory(.playAndRecord, mode: .default, options: [.allowBluetooth, ])
                print("âœ… ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
            }
                //.defaultToSpeakerã¯ã€ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ãŒæ¥ç¶šã•ã‚Œã¦ãªã„ã¨ãã«iPhoneã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’ä½¿ã†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            try session.setActive(true, options: .notifyOthersOnDeactivation) // ã“ã“ã§éåŒæœŸã§å®Œäº†ã‚’å¾…ã¤ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚‚æ¤œè¨
            print("âœ… ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚AudioSessionè¨­å®šå®Œäº†")
        } catch {
            print("âŒ ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚AudioSessionè¨­å®šã‚¨ãƒ©ãƒ¼: \(error)")
        }
    }
    
    init() {
        self.spectrumLevels = Array(repeating: 0.0, count: barCount)
        self.mainMixer = audioEngine.mainMixerNode
        
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ã‚ã‚‰ã‹ã˜ã‚ç™»éŒ²
        UserDefaults.standard.register(defaults: [
            //            "eqFrequency": 1000,
            //            "eqGain": 10,
            //            "eqWidth": 1.5,
            "lowGain": 0.0,
            "midGain": 0.0,
            "highGain": 0.0,
            "masterVolume": 1.0,
            "listenMode": "ambient"
        ])
        
        self.lowGain = UserDefaults.standard.float(forKey: "lowGain")
        self.midGain = UserDefaults.standard.float(forKey: "midGain")
        self.highGain = UserDefaults.standard.float(forKey: "highGain")
        self.masterVolume = UserDefaults.standard.float(forKey: "masterVolume")
        if let savedModeString = UserDefaults.standard.string(forKey: "listenMode") {
            // èª­ã¿å‡ºã—ãŸæ–‡å­—åˆ—ã‹ã‚‰ listenMode ã‚’åˆæœŸåŒ–ã™ã‚‹
            // Raw Valueã‹ã‚‰enumã‚’åˆæœŸåŒ–ã™ã‚‹failable initializerã‚’ä½¿ã†
            self.selectedListenMode = listenMode(rawValue: savedModeString)  ?? .ambient //ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’æŒ‡å®š
        } else {
            // ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ã†
            self.selectedListenMode = .ambient
        }

        
        setupAudioSessionForAppLaunch(newListenMode: self.selectedListenMode)
        setupEQ()
    }
    
    private func setupEQ() {
        eqNode.globalGain = 0 // å…¨ä½“ã‚²ã‚¤ãƒ³
        
        // ä½éŸ³
        let lowBand = eqNode.bands[0]
        lowBand.filterType = .parametric
        lowBand.frequency = 200.0
        lowBand.bandwidth = 1.0
        lowBand.gain = lowGain
        lowBand.bypass = false
        
        // ä¸­éŸ³ï¼ˆæ—¢å­˜ã®1kHzï¼‰
        let midBand = eqNode.bands[1]
        midBand.filterType = .parametric
        midBand.frequency = 1000.0
        midBand.bandwidth = 1.0
        midBand.gain = midGain
        midBand.bypass = false
        
        // é«˜éŸ³
        let highBand = eqNode.bands[2]
        highBand.filterType = .parametric
        highBand.frequency = 4000.0
        highBand.bandwidth = 1.0
        highBand.gain = highGain
        highBand.bypass = false
    }
    
    
    func isHeadphonesConnected() -> Bool {
        let route = AVAudioSession.sharedInstance().currentRoute
        for output in route.outputs {
            if output.portType == .headphones || output.portType == .bluetoothA2DP || output.portType == .bluetoothLE || output.portType == .bluetoothHFP {
                return true
            }
        }
        return false
    }
    
    func startMicrophone(completion: @escaping (Bool) -> Void) {
        if isRunning {
            completion(true)
            return
        }

//        setupAudioSessionForAppLaunch()
        
        DispatchQueue.global(qos: .userInitiated).async {

            if !self.isHeadphonesConnected() {
                print("ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã‚’æ¥ç¶šã—ã¦ãã ã•ã„")
                DispatchQueue.main.async {
                    completion(false)
                }
                return
            }

            let inputNode = self.audioEngine.inputNode
            let format = inputNode.outputFormat(forBus: 0)
            let output = self.audioEngine.outputNode

            self.mainMixer.outputVolume = self.masterVolume
            self.setupEQ()
            self.audioEngine.attach(self.eqNode)
            self.audioEngine.connect(inputNode, to: self.eqNode, format: format)
            self.audioEngine.connect(self.eqNode, to: self.mainMixer, format: format)
            self.audioEngine.connect(self.mainMixer, to: output, format: format)

            self.audioEngine.prepare()
//            Thread.sleep(forTimeInterval: 0.1) // â†ã“ã‚Œã‚’å…¥ã‚Œãªã„ã¨åˆå›éŒ²éŸ³ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆaudioEngine.start()ï¼‰ã§ç©ºæŒ¯ã‚Šã™ã‚‹

            do {
                try self.audioEngine.start()
                DispatchQueue.main.async {
                    self.isRunning = true
                    print("ğŸ™ï¸ ãƒã‚¤ã‚¯ï¼†éŸ³é‡ç›£è¦–é–‹å§‹")
                    completion(true)
                }
            } catch {
                print("âŒ AudioEngineèµ·å‹•ã‚¨ãƒ©ãƒ¼: \(error)")
                DispatchQueue.main.async {
                    completion(false)
                }
            }
        }
    }
    
//    func processAudioBuffer(buffer: AVAudioPCMBuffer) {
//        guard let channelData = buffer.floatChannelData?[0] else { return }
//        let frameCount = Int(buffer.frameLength)
//        var window = [Float](repeating: 0, count: frameCount)
//        var spectrum = [Float](repeating: 0.0, count: barCount)
//        
//        // Hannã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§æ»‘ã‚‰ã‹ã«
//        vDSP_hann_window(&window, vDSP_Length(frameCount), Int32(vDSP_HANN_NORM))
//        var samples = [Float](repeating: 0.0, count: frameCount)
//        vDSP_vmul(channelData, 1, window, 1, &samples, 1, vDSP_Length(frameCount))
//        
//        // FFTç”¨ã«è¤‡ç´ æ•°ã¸å¤‰æ›
//        let log2n = UInt(round(log2(Float(frameCount))))
//        let fftSetup = vDSP_create_fftsetup(log2n, FFTRadix(kFFTRadix2))!
//        var realp = [Float](repeating: 0.0, count: frameCount / 2)
//        var imagp = [Float](repeating: 0.0, count: frameCount / 2)
//        
//        realp.withUnsafeMutableBufferPointer { realPointer in
//            imagp.withUnsafeMutableBufferPointer { imagPointer in
//                var splitComplex = DSPSplitComplex(realp: realPointer.baseAddress!, imagp: imagPointer.baseAddress!)
//                
//                samples.withUnsafeMutableBufferPointer { ptr in
//                    ptr.baseAddress!.withMemoryRebound(to: DSPComplex.self, capacity: frameCount) { complexPtr in
//                        vDSP_ctoz(complexPtr, 2, &splitComplex, 1, vDSP_Length(frameCount / 2))
//                    }
//                }
//                
//                // FFTå®Ÿè¡Œ
//                vDSP_fft_zrip(fftSetup, &splitComplex, 1, log2n, FFTDirection(FFT_FORWARD))
//                
//                // ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã«å¤‰æ›
//                var magnitudes = [Float](repeating: 0.0, count: frameCount / 2)
//                vDSP_zvmags(&splitComplex, 1, &magnitudes, 1, vDSP_Length(frameCount / 2))
//                
//                // ã“ã“ã§spectrumè¨ˆç®—ï¼ˆãƒãƒ³ãƒ‰åˆ†ã‘ï¼‰
//                let bandSize = magnitudes.count / barCount
//                for i in 0..<barCount {
//                    let start = i * bandSize
//                    let end = start + bandSize
//                    let slice = magnitudes[start..<min(end, magnitudes.count)]
//                    let avg = sqrt(slice.reduce(0, +) / Float(slice.count))
//                    spectrum[i] = min(max(avg * 3, 0), 1)
//                    //                    print("Band \(i): avg = \(avg), scaled = \(avg * 3)")
//                }
//                
//                DispatchQueue.main.async {
//                    for i in 1..<self.barCount {
//                        // æ—§å€¤ã«å¯¾ã—ã¦é‡ã¿ã‚’åŠ ãˆã¦æ›´æ–°ï¼ˆÎ±=0.2ãã‚‰ã„ï¼‰
//                        let current = self.spectrumLevels[i]
//                        self.spectrumLevels[i] = current * 0.8 + spectrum[i] * 0.2
//                    }
//                }
//            }
//        }
//        
//        
//        vDSP_destroy_fftsetup(fftSetup)
//        
//    }
    
    func stopMicrophone() {
        if !isRunning { return }
        audioEngine.inputNode.removeTap(onBus: 0)
        audioEngine.stop()
        audioEngine.reset()
        currentLevel = 0.0
        isRunning = false
        print("ğŸ›‘ ãƒã‚¤ã‚¯åœæ­¢")
    }
    
    func startMonitoringLevel() {
        if isMonitoring { return }
        isMonitoring = true

        audioEngine.mainMixerNode.installTap(onBus: 0, bufferSize: 1024, format: nil) { buffer, _ in
            guard let channelData = buffer.floatChannelData?[0] else { return }
            let channelDataValue = stride(from: 0,
                                            to: Int(buffer.frameLength),
                                            by: buffer.stride).map { channelData[$0] }

            let rms = sqrt(channelDataValue.map { $0 * $0 }.reduce(0, +) / Float(buffer.frameLength))
            let avgPower = 20 * log10(rms)

            let meterLevel = self.normalizedPowerLevel(from: avgPower)
            
            // UIæ›´æ–°ã¯ã›ãšã«ã€ç”Ÿã®ãƒ¬ãƒ™ãƒ«ã ã‘ã‚’ä¸€æ™‚ä¿å­˜
            self._currentRawLevel = meterLevel
        }
        
        // ã‚¿ã‚¤ãƒãƒ¼ã‚’é–‹å§‹ã—ã¦ã€UIã‚’å®šæœŸçš„ã«æ›´æ–°ã™ã‚‹
        // ä¾‹: 1ç§’é–“ã«30å›ï¼ˆ1.0 / 30.0 = ç´„0.033ç§’ã”ã¨ï¼‰æ›´æ–°
        levelUpdateTimer = Timer.scheduledTimer(withTimeInterval: 1.0 / 30.0, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            // ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§UIã‚’æ›´æ–°
            DispatchQueue.main.async {
                if self.isRunning {
                    self.currentLevel = self._currentRawLevel
                }
            }
        }
    }
    
    func stopMonitoringLevel() {
        if isMonitoring {
            audioEngine.mainMixerNode.removeTap(onBus: 0)
            currentLevel = 0.0
            isMonitoring = false
            // ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢ã™ã‚‹ã®ã‚‚å¿˜ã‚Œãšã«ï¼
            levelUpdateTimer?.invalidate()
            levelUpdateTimer = nil
        }
    }

    // æ­£è¦åŒ–ï¼ˆdBã‚’0ã€œ1ã«å¤‰æ›ï¼‰
    private func normalizedPowerLevel(from decibels: Float) -> Float {
        let minDb: Float = -80
        if decibels < minDb {
            return 0.0
        } else if decibels >= 0 {
            return 1.0
        } else {
            return (decibels + abs(minDb)) / abs(minDb)
        }
    }
}
